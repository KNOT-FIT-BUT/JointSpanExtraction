{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the no-answer performance for SQ2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw the inferior performance of compound model caused by weaker classification accuracy. In the paper we follow the BERT's approach for the independent model (using score score = start_logit[0] + end_logit[0] as no-answer logit), and use score = logit\\[0,0\\] for joint/compound models as a no-answer logit. Note the bert's preprocessing finds optimal threshold on dev data over the difference of the lowest no-answer score and best span answer score (no_ans_score=score-best_span_score) in all windows (subparts of the input that satisfy model's input length constraint) of the example.\n",
    "\n",
    "Here, we investigate what happens if we fuse no-answer scores from independent heads (both start/end probability spaces are extended with no answer), joint heads score and best span answer score via trivial logistic regression and see whether there is any difference than when using official BERT's approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anonymized_name/research/JointSpanExtraction\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import math\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "def colorize(string,color=\"red\"):\n",
    "     return f\"<span style=\\\"color:{color}\\\">{string}</span>\"\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets try it out for best and worst models \n",
    "(same code is repeated down for the worst model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# This checkpoint: EM_74.14_F1_76.85_L_2.63\n",
    "with open(\"squad2_scores_and_gts_best_model.pkl\",\"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores,labels = [],[]\n",
    "for _id, l in data['labels'].items():\n",
    "    labels.append(l)\n",
    "    scores.append(data['scores'][_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X = torch.FloatTensor(scores)\n",
    "Y = torch.BoolTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6124, -2.5779, -3.0910,  9.5602],\n",
      "        [ 1.2289, -1.8597, -1.9223,  9.6860],\n",
      "        [ 9.1972,  4.7305,  4.6422,  7.0565],\n",
      "        ...,\n",
      "        [ 8.6794,  5.2043,  5.4920,  4.8284],\n",
      "        [ 6.4353,  3.7706,  4.1866,  2.2437],\n",
      "        [ 7.9825,  4.8924,  5.5472,  3.2727]]) tensor([False, False, False,  ...,  True,  True,  True])\n",
      "torch.Size([11873, 4]) torch.Size([11873])\n"
     ]
    }
   ],
   "source": [
    "print(X,Y)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstrainedLR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(4,1,bias=True)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        return self.linear(X).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(M,X,Y):\n",
    "    M.eval()\n",
    "    odds = M(X)\n",
    "    predictions=odds>0.\n",
    "    accuracy = (predictions==Y).sum()/float(len(Y))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2337)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(ConstrainedLR(),X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(0.8011): 100%|██████████| 100/100 [00:00<00:00, 514.69it/s]\n",
      "tensor(0.8028): 100%|██████████| 100/100 [00:00<00:00, 520.81it/s]\n",
      "tensor(0.3003):   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'linear.weight': [[0.5758213996887207, -0.12292639166116714, -0.1670505702495575, -0.4772215783596039]], 'linear.bias': [0.08077636361122131]}\n",
      "{'linear.weight': [[0.43374213576316833, 0.03123548999428749, -0.14522607624530792, -0.40512537956237793]], 'linear.bias': [0.1149904802441597]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(0.8014): 100%|██████████| 100/100 [00:00<00:00, 460.04it/s]\n",
      "tensor(0.8035): 100%|██████████| 100/100 [00:00<00:00, 406.44it/s]\n",
      "tensor(0.8025):  22%|██▏       | 22/100 [00:00<00:00, 217.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'linear.weight': [[0.3941035866737366, -0.145783931016922, 0.07665596902370453, -0.3855445086956024]], 'linear.bias': [0.08933649957180023]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(0.8026): 100%|██████████| 100/100 [00:00<00:00, 406.51it/s]\n",
      "tensor(0.8014): 100%|██████████| 100/100 [00:00<00:00, 477.57it/s]\n",
      "tensor(0.8032): 100%|██████████| 100/100 [00:00<00:00, 616.83it/s]\n",
      "tensor(0.8018): 100%|██████████| 100/100 [00:00<00:00, 701.04it/s]\n",
      "tensor(0.8023): 100%|██████████| 100/100 [00:00<00:00, 401.65it/s]\n",
      "tensor(0.8021): 100%|██████████| 100/100 [00:00<00:00, 592.86it/s]\n",
      "tensor(0.8038): 100%|██████████| 100/100 [00:00<00:00, 709.71it/s]\n",
      "tensor(0.8024):  25%|██▌       | 25/100 [00:00<00:00, 247.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'linear.weight': [[0.42036378383636475, -0.20511984825134277, 0.10401123017072678, -0.40278103947639465]], 'linear.bias': [0.12815922498703003]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(0.8027): 100%|██████████| 100/100 [00:00<00:00, 355.90it/s]\n",
      "tensor(0.8033): 100%|██████████| 100/100 [00:00<00:00, 396.62it/s]\n",
      "tensor(0.8027): 100%|██████████| 100/100 [00:00<00:00, 532.10it/s]\n",
      "tensor(0.8036): 100%|██████████| 100/100 [00:00<00:00, 678.78it/s]\n",
      "tensor(0.8023): 100%|██████████| 100/100 [00:00<00:00, 420.22it/s]\n",
      "tensor(0.8032): 100%|██████████| 100/100 [00:00<00:00, 411.34it/s]\n",
      "tensor(0.8022): 100%|██████████| 100/100 [00:00<00:00, 615.76it/s]\n",
      "tensor(0.8028): 100%|██████████| 100/100 [00:00<00:00, 503.38it/s]\n",
      "tensor(0.8032): 100%|██████████| 100/100 [00:00<00:00, 483.20it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "def run_training():\n",
    "    STEPS=100\n",
    "    model =  ConstrainedLR()\n",
    "    model = model.train()\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=0.3)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "                    opt,\n",
    "                    num_warmup_steps=10,\n",
    "                    num_training_steps=STEPS\n",
    "                )\n",
    "\n",
    "    best_acc= 0\n",
    "    best_r = None\n",
    "    iterator = tqdm(range(STEPS))\n",
    "    labels=Y.float()\n",
    "    for i in iterator:\n",
    "        log_odds = model(X)\n",
    "        l_list = F.binary_cross_entropy_with_logits(log_odds, labels, reduction='none')\n",
    "        l = l_list.mean()\n",
    "        l.backward()\n",
    "        opt.step()\n",
    "        scheduler.step()\n",
    "        opt.zero_grad()\n",
    "        if i % 1 == 0:\n",
    "            r = { k: v.tolist() for k,v in dict(model.named_parameters()).items()}\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                acc = evaluate_model(model, X, Y)\n",
    "            model.train()\n",
    "            if acc>best_acc:\n",
    "                iterator.set_description(str(acc))\n",
    "                best_acc = acc\n",
    "                best_r = r\n",
    "    return best_acc, best_r\n",
    "total_best_acc, total_best_r = 0.,None\n",
    "for _ in range(20):\n",
    "    acc,r = run_training()\n",
    "    if acc>total_best_acc:\n",
    "        print(r)\n",
    "        total_best_acc=acc\n",
    "        total_best_r=r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total best:\n",
      "tensor(0.8038)\n",
      "{'linear.weight': [[0.42036378383636475, -0.20511984825134277, 0.10401123017072678, -0.40278103947639465]], 'linear.bias': [0.12815922498703003]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Total best:\")\n",
    "print(total_best_acc)\n",
    "print(total_best_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Solution from the BERT's source get_predictions method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8022)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_model = ConstrainedLR()\n",
    "found_model.linear.weight[0]=torch.FloatTensor([1.,0.,0.,-1,])\n",
    "found_model.linear.bias[0] =0.\n",
    "\n",
    "found_best_threshold=-0.752\n",
    "evaluate_model(found_model,X+found_best_threshold,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion 1__: For the best model, solution is approximately the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# This checkpoint: EM_72.62_F1_75.05_L_2.72\n",
    "\n",
    "with open(\"squad2_scores_and_gts_worst_model.pkl\",\"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores,labels = [],[]\n",
    "for _id, l in data['labels'].items():\n",
    "    labels.append(l)\n",
    "    scores.append(data['scores'][_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X = torch.FloatTensor(scores)\n",
    "Y = torch.BoolTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7163, -2.4542, -2.9251, 10.8823],\n",
      "        [ 0.4709, -2.9283, -3.2450,  8.8130],\n",
      "        [ 2.2096, -1.1581, -1.6156,  8.7181],\n",
      "        ...,\n",
      "        [10.4564,  5.8908,  5.2725,  7.3239],\n",
      "        [ 6.2576,  2.5990,  2.7125,  4.5220],\n",
      "        [ 8.7057,  4.2362,  4.1163,  4.1985]]) tensor([False, False, False,  ...,  True,  True,  True])\n",
      "torch.Size([11873, 4]) torch.Size([11873])\n"
     ]
    }
   ],
   "source": [
    "print(X,Y)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstrainedLR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(4,1,bias=True)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        return self.linear(X).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(M,X,Y):\n",
    "    M.eval()\n",
    "    odds = M(X)\n",
    "    predictions=odds>0.\n",
    "    accuracy = (predictions==Y).sum()/float(len(Y))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4995)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(ConstrainedLR(),X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(0.7862): 100%|██████████| 100/100 [00:00<00:00, 551.49it/s]\n",
      "tensor(0.7859): 100%|██████████| 100/100 [00:00<00:00, 696.45it/s]\n",
      "tensor(0.6734):   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'linear.weight': [[0.5943999290466309, -0.20816883444786072, -0.1340014934539795, -0.4769420027732849]], 'linear.bias': [0.021049603819847107]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(0.7846): 100%|██████████| 100/100 [00:00<00:00, 511.23it/s]\n",
      "tensor(0.7855): 100%|██████████| 100/100 [00:00<00:00, 643.86it/s]\n",
      "tensor(0.7860): 100%|██████████| 100/100 [00:00<00:00, 639.13it/s]\n",
      "tensor(0.7864): 100%|██████████| 100/100 [00:00<00:00, 729.83it/s]\n",
      "tensor(0.7856): 100%|██████████| 100/100 [00:00<00:00, 646.69it/s]\n",
      "tensor(0.7762):   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'linear.weight': [[0.5754302144050598, -0.14204084873199463, -0.16680869460105896, -0.44428592920303345]], 'linear.bias': [-0.07883349061012268]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(0.7867): 100%|██████████| 100/100 [00:00<00:00, 592.41it/s]\n",
      "tensor(0.7858): 100%|██████████| 100/100 [00:00<00:00, 724.38it/s]\n",
      "tensor(0.7591):   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'linear.weight': [[0.3304724097251892, -0.03998826816678047, -0.004543735645711422, -0.4211843013763428]], 'linear.bias': [0.7147210836410522]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(0.7866): 100%|██████████| 100/100 [00:00<00:00, 586.22it/s]\n",
      "tensor(0.7860): 100%|██████████| 100/100 [00:00<00:00, 755.22it/s]\n",
      "tensor(0.7854): 100%|██████████| 100/100 [00:00<00:00, 707.60it/s]\n",
      "tensor(0.7858): 100%|██████████| 100/100 [00:00<00:00, 816.33it/s]\n",
      "tensor(0.7866): 100%|██████████| 100/100 [00:00<00:00, 687.89it/s]\n",
      "tensor(0.7853): 100%|██████████| 100/100 [00:00<00:00, 757.34it/s]\n",
      "tensor(0.7863): 100%|██████████| 100/100 [00:00<00:00, 645.24it/s]\n",
      "tensor(0.7862): 100%|██████████| 100/100 [00:00<00:00, 732.73it/s]\n",
      "tensor(0.7863): 100%|██████████| 100/100 [00:00<00:00, 655.45it/s]\n",
      "tensor(0.7861): 100%|██████████| 100/100 [00:00<00:00, 619.61it/s]\n",
      "tensor(0.7864): 100%|██████████| 100/100 [00:00<00:00, 651.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "def run_training():\n",
    "    STEPS=100\n",
    "    model =  ConstrainedLR()\n",
    "    model = model.train()\n",
    "    opt = torch.optim.SGD(model.parameters(), lr=0.3)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "                    opt,\n",
    "                    num_warmup_steps=10,\n",
    "                    num_training_steps=STEPS\n",
    "                )\n",
    "\n",
    "    best_acc= 0\n",
    "    best_r = None\n",
    "    iterator = tqdm(range(STEPS))\n",
    "    labels=Y.float()\n",
    "    for i in iterator:\n",
    "        log_odds = model(X)\n",
    "        l_list = F.binary_cross_entropy_with_logits(log_odds, labels, reduction='none')\n",
    "        l = l_list.mean()\n",
    "        l.backward()\n",
    "        opt.step()\n",
    "        scheduler.step()\n",
    "        opt.zero_grad()\n",
    "        if i % 1 == 0:\n",
    "            r = { k: v.tolist() for k,v in dict(model.named_parameters()).items()}\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                acc = evaluate_model(model, X, Y)\n",
    "            model.train()\n",
    "            if acc>best_acc:\n",
    "                iterator.set_description(str(acc))\n",
    "                best_acc = acc\n",
    "                best_r = r\n",
    "    return best_acc, best_r\n",
    "total_best_acc, total_best_r = 0.,None\n",
    "for _ in range(20):\n",
    "    acc,r = run_training()\n",
    "    if acc>total_best_acc:\n",
    "        print(r)\n",
    "        total_best_acc=acc\n",
    "        total_best_r=r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total best:\n",
      "tensor(0.7867)\n",
      "{'linear.weight': [[0.3304724097251892, -0.03998826816678047, -0.004543735645711422, -0.4211843013763428]], 'linear.bias': [0.7147210836410522]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Total best:\")\n",
    "print(total_best_acc)\n",
    "print(total_best_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Solution from the BERT's source get_predictions method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7824)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_model = ConstrainedLR()\n",
    "found_model.linear.weight[0]=torch.FloatTensor([1.,0.,0.,-1,])\n",
    "found_model.linear.bias[0] =0.\n",
    "\n",
    "found_best_threshold=-0.945\n",
    "evaluate_model(found_model,X+found_best_threshold,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion 2__: For the worst model, the fused solution is slightly better, but still much weaker than (even the worst) no-answer accuracy of the independent model! These are all our 10 results for the no-answer accuracy of __independent__ models:\n",
    "```\n",
    "0.7930598838\n",
    "0.7954181757\n",
    "0.7950812768\n",
    "0.7969342205\n",
    "0.7965973217\n",
    "0.7988713889\n",
    "0.8015665796\n",
    "0.7997978607\n",
    "0.8077992083\n",
    "0.8042617704\n",
    "```\n",
    "__average__:0.7989387686\n",
    "__std__:0.004543938582\n",
    "\n",
    "the difference is definitely statistically significant!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jointqa",
   "language": "python",
   "name": "jointqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
